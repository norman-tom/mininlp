{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DTransformer(\n",
       "  (_embedding): Embedding(\n",
       "    (_token_embedding): Embedding(105, 512)\n",
       "  )\n",
       "  (_decoders): ModuleList(\n",
       "    (0-5): 6 x Decoder(\n",
       "      (_laynorm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (_laynorm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (_mmha): MultiHeadAttention(\n",
       "        (_projection): ModuleList(\n",
       "          (0-2): 3 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (_reprojection): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (_mha): MultiHeadAttention(\n",
       "        (_projection): ModuleList(\n",
       "          (0-2): 3 x Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (_reprojection): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (_ff): FeedForward(\n",
       "        (_laynorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (_dropout): Dropout(p=0.2, inplace=False)\n",
       "        (_ff): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (_lang_head): LanguageHead(\n",
       "    (_projection): Linear(in_features=512, out_features=105, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mininlp.transformer import DTransformer\n",
    "import json\n",
    "from mininlp.data import Tokenizer, SequenceDataset\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "VERSION = 0.1\n",
    "MODEL_NAME = f'decoder_transformer_v{VERSION}'\n",
    "config = json.load(open(f\"../models/{MODEL_NAME}.json\"))\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.load(os.path.join('../models', 'tokenizer.pkl'))\n",
    "\n",
    "model = DTransformer(\n",
    "    config['layers'], \n",
    "    config['embedding_dim'], \n",
    "    len(tokenizer), \n",
    "    config['seq_len'], \n",
    "    config['heads'], \n",
    "    config['factor'],\n",
    "    True)\n",
    "state_dict = torch.load(f\"../models/{MODEL_NAME}.pt\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.load(\"../models/tokenizer.pkl\")\n",
    "dataset = SequenceDataset('../data/anna.txt', tokenizer, config['seq_len'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    input = dataset[0][0].unsqueeze(0)\n",
    "    output = model(input.to('cuda'))\n",
    "    probs = F.softmax(output[0, -1, :], dim=0)\n",
    "    probs = probs.detach().cpu()\n",
    "    \n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(tokenizer.decode(torch.tensor(range(len(probs)))), probs)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.decode(dataset[0][0])\n",
    "text += [\"<msk>\"]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prompt = dataset[0][0].unsqueeze(0).to('cuda')\n",
    "    text += tokenizer.decode(model.generate(prompt, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> all,\n",
      "ridiculous people, who believe that one husband ought to live with the\n",
      "one wife whom he has lawfully married; that a girl should be innocent, a\n",
      "woman modest, and a man manly, self-controlled, and strong; that one\n",
      "ought to bring up one's children, earn one's bread, and pay one's debts;\n",
      "and various similar absurdities. This was the class of old-fashioned and\n",
      "ridiculous people. But there was another class of people, the real\n",
      "people. To this class they all belonged, and in it the great thing was\n",
      "to be elegant, generous, plucky, gay, to abandon oneself without a blush\n",
      "to every passion, and to laugh at everything else.\n",
      "\n",
      "For the first moment only, Vronsky was startled after the impression of\n",
      "a quite different world that he had brought with him from Moscow. But\n",
      "immediately as though slipping his feet into old slippers, he dropped\n",
      "back into the light-hearted, pleasant world he had always lived in.\n",
      "\n",
      "The coffee was never really made, but spluttered over every one, and\n",
      "boiled away, doing just wha<msk>t he had done down riah, \n",
      "AHNTIggh-ch.\n",
      "\n",
      "A DChho Ipgyo.\n",
      "\n",
      "Obgyphbeory,-DCghhp Vawfupny,mya, Soah- StAIRPhIIShaof, h, Shhtmsaft\n",
      "wey-fee eisheoldhna\n",
      "rabbuldCombeout,RyaS thfv, DombhI sawfre, thwri, Leoshraoms shyvhhh-heslui\n",
      "malowte?\n",
      " Dawcy wdyshe\n",
      "tady,\n",
      "chmbays,- Sthh- Tueubh Ascuh S\n",
      "choh - Yomopsyehs, tocb.8.\" Sitosbe, I groat, Srohh,-\" aSpoohjy. RihpShap toafi,\n",
      "daahot, pecuieem allaaiesla soo buaeb, yevzh,\n",
      "SReho fema trub Fbet, athwfondy patii.h, occhok,- \"he saaaft, chaleow,\n",
      "aptoai,hbe Aueo cuuuie\n"
     ]
    }
   ],
   "source": [
    "text = [t for t in text if t != \"<pad>\"]\n",
    "print(\"\".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 16, 18, 20]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "arr[5:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "\n",
    "data = torch.tensor([4.0, 6, 8, 10, 12, 14, 16, 18, 20]).reshape(3,-1)\n",
    "labels = torch.tensor([10.0, 20, 30]).reshape(3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0627],\n",
       "        [-3.9297],\n",
       "        [-5.7967]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Linear(3, 1)\n",
    "model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non gradient accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-573.5305, -669.2493, -764.9683]]), tensor([-47.8594]))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.mse_loss(model(data), labels)\n",
    "loss.backward()\n",
    "model.weight.grad, model.bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.]]), tensor([0.]))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "model.weight.grad = torch.zeros_like(model.weight.grad)\n",
    "model.bias.grad = torch.zeros_like(model.bias.grad)\n",
    "model.weight.grad, model.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-32.1672, -48.2509, -64.3345]]), tensor([-8.0418]))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.mse_loss(model(data[i,]), labels[i,]) / 3\n",
    "loss.backward()\n",
    "i += 1\n",
    "model.weight.grad, model.bias.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
